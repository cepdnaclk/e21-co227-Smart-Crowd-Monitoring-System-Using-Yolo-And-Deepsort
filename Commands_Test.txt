.\.venv\Scripts\Activate.ps1
python -m pytest -q

# from project root (or from tests/, both are fine)
$env:RUN_AI_TESTS = "1"
python -m pytest tests\test_ai_smoke.py -q
Remove-Item Env:RUN_AI_TESTS

$env:USE_LOCAL_PG = '1'
$env:DB_HOST = 'localhost'
$env:DB_PORT = '5432'
$env:DB_NAME = 'crowd_monitor'
$env:DB_USER = 'postgres'
$env:DB_PASS = '111@Postgres'   

python -m pytest tests\integration\test_api_db_integration.py -q -rs


Per-person integration tests
Anjana (Backend logic + Server + UI design)
Focus: counts per building, enter/exit, detection threshold from config, and API response shape.

Add:

tests/integration/test_api_db_integration.py
Spin up Postgres container (testcontainers).
Create schema:
buildings(building_id, building_name)
crowd_counts(id, building_id, current_count, timestamp)
Seed rows and verify:
GET /crowd returns latest counts and includes threshold from config.json.
GET /crowd/history returns within time ranges.
Use FastAPI TestClient and ensure you reload api after patching env vars (so startup connects to the container).
tests/integration/test_thresholds_config_integration.py
Override config (temp copy or monkeypatch the loaded config dict) so building thresholds differ.
GET /crowd and assert thresholds reflect config. This validates config-to-API wiring.
You already have unit tests for these behaviors; this confirms API + real DB path works too.

Namidu (AI systems + frontend buildings/crowd + API)
Focus: AI pipeline sanity + API contract for frontend.

Add:

tests/integration/test_ai_pipeline_smoke.py (optional)
Marked with @pytest.mark.ai @pytest.mark.integration.
Use a tiny clip or 10 generated frames and run YOLO with device="cpu" at stride (sample every Nth) to keep it fast.
Track with DeepSort and assert: no crashes, non-empty structure, and at least some “person” boxes are detected.
Keep it smoke-level; no strict accuracy assertions (these are often flaky).
tests/integration/test_api_contract_frontend.py
Validate /crowd response includes the fields frontend uses (buildingId, buildingName, currentCount, timestamp, threshold).
This safeguards the API contract that the frontend depends on.
Note: Gate heavy AI tests via RUN_AI_TESTS=1 to avoid slowing normal runs (you already have this pattern).

Janidu (Performance Optimization — Threading + Frontend graph + API)
Focus: threading integration (multiple buildings in parallel) and DB updates.

Add:

tests/integration/test_threaded_building_pipeline.py
Use fakes for camera streams (a stubbed VideoCapture that yields a fixed number of frames).
Fake YOLO/DeepSort: return predictable “person” detections with centers crossing the line to increment counters.
Spin up 2 buildings with their own threads (like process_building), run briefly.
Patch DB insert to record calls (or use testcontainers Postgres if you want the full path).
Assert:
shared_counters[building_id] > 0
No deadlocks; threads finish.
DB received inserts at ~expected intervals.
tests/integration/test_db_writer_integration.py
Use Postgres container and real CrowdDatabase with small update_interval.
Call insert_multiple_counts across two intervals and assert rows exist for each batch.
This proves interval batching under “production-like” DB.
You already have unit-level tests for threading and interval; these validate the behavior through the actual types (and optionally the real DB).

KT (Network Management — receiving footage, controlling frame rate + DB + frontend alerts)
Focus: open/reconnect behavior + frame sampling + alert thresholds.

Add:

tests/integration/test_stream_open_retry_integration.py
Use network_utils.open_capture_with_retry with a fake factory that fails N times then succeeds; ensure pipeline continues once opened (integrate a minimal loop step).
tests/integration/test_frame_rate_integration.py
Run a mini-loop over 10 dummy frames; only process every 3rd using the helper (already added).
Verify that processing count matches expected sampling.
tests/integration/test_alerts_thresholds_integration.py
Seed DB with counts that cross thresholds; GET /crowd and assert that rows containing counts above threshold would trigger an alert on the frontend (even if not implemented as an endpoint, you can compute “shouldAlert = currentCount >= threshold” and validate correctness).
Suggested file structure
tests/
conftest.py (already ensures root on sys.path)
unit/ … (your existing fast unit tests)
integration/
test_api_db_integration.py
test_db_writer_integration.py
test_threaded_building_pipeline.py
test_stream_open_retry_integration.py
test_frame_rate_integration.py
test_ai_pipeline_smoke.py (optional, ai+slow)
test_alerts_thresholds_integration.py
Reusable fixtures (sketch)
tests/integration/conftest.py:
A session-scoped pg_container fixture (testcontainers) exposing DSN.
A function-scoped seeded_db fixture creating schema and seed data.
A helper to patch env vars and reload api to connect to the container.
Optional: fakes for VideoCapture, YOLO, DeepSort for deterministic runs.